"""
Demo Script for ML System Enhancements
Demonstrates all 6 enhancements:
1. Batch prediction endpoint
2. Model versioning and A/B testing
3. WebSocket streaming
4. Automated retraining
5. GPU acceleration
6. Multi-model ensemble voting
"""

import asyncio
import time
import json
from datetime import datetime

# Import enhancement modules
from model_manager import ModelManager
from retraining_pipeline import TrainingDataCollector, ModelRetrainer
from orchestrator import MLEnsemble, Opportunity, ChainType


def print_section(title: str):
    """Print a formatted section header"""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70 + "\n")


def demo_model_versioning():
    """Demo 1 & 2: Model Versioning and A/B Testing"""
    print_section("DEMO 1 & 2: Model Versioning and A/B Testing")
    
    manager = ModelManager()
    
    # Register multiple model versions
    print("üìù Registering model versions...")
    
    manager.register_model(
        model_type="xgboost",
        model_path="data/models/xgboost_v1.0.0.json",
        version="v1.0.0",
        metrics={"accuracy": 0.87, "precision": 0.85, "recall": 0.89},
        activate=True
    )
    
    manager.register_model(
        model_type="xgboost",
        model_path="data/models/xgboost_v1.1.0.json",
        version="v1.1.0",
        metrics={"accuracy": 0.89, "precision": 0.88, "recall": 0.90},
        activate=False
    )
    
    manager.register_model(
        model_type="onnx",
        model_path="data/models/onnx_v1.0.0.onnx",
        version="v1.0.0",
        metrics={"accuracy": 0.86, "precision": 0.84, "recall": 0.88},
        activate=True
    )
    
    print("‚úÖ Registered 3 model versions\n")
    
    # List versions
    print("üìã Listing XGBoost versions:")
    for v in manager.list_versions("xgboost"):
        status = "‚úÖ ACTIVE" if v.is_active else "‚≠ï Inactive"
        print(f"   {status} {v.version} - Accuracy: {v.metrics.get('accuracy', 0):.2%}")
    
    # Setup A/B test
    print("\nüî¨ Setting up A/B test...")
    manager.setup_ab_test(
        model_type="xgboost",
        version_a="v1.0.0",
        version_b="v1.1.0",
        traffic_split=(0.7, 0.3)  # 70% v1.0.0, 30% v1.1.0
    )
    
    # Simulate traffic distribution
    print("\nüìä Simulating 100 requests with A/B split:")
    version_counts = {"v1.0.0": 0, "v1.1.0": 0}
    
    for i in range(100):
        selected = manager.select_model_for_request("xgboost")
        if selected:
            version_counts[selected.version] += 1
    
    for version, count in version_counts.items():
        print(f"   {version}: {count} requests ({count}%)")
    
    # Get summary
    print("\nüìà Model Summary:")
    summary = manager.get_summary()
    print(json.dumps(summary, indent=2))


def demo_ensemble_voting():
    """Demo 6: Multi-Model Ensemble Voting"""
    print_section("DEMO 6: Multi-Model Ensemble Voting")
    
    # Create sample opportunity
    opportunity = Opportunity(
        route_id="usdc_usdt_2hop",
        tokens=["USDC", "USDT", "USDC"],
        dexes=["quickswap", "sushiswap"],
        input_amount=1000.0,
        expected_output=1012.0,
        gas_estimate=350000,
        profit_usd=12.0,
        confidence_score=0.85,
        timestamp=int(time.time()),
        chain=ChainType.POLYGON
    )
    
    # Test different voting strategies
    strategies = ["weighted", "majority", "unanimous"]
    
    print("üó≥Ô∏è  Testing voting strategies:\n")
    
    for strategy in strategies:
        ensemble = MLEnsemble(use_gpu=False, voting_strategy=strategy)
        
        # Since models aren't loaded, simulate predictions
        print(f"Strategy: {strategy.upper()}")
        print(f"   Description: ", end="")
        
        if strategy == "weighted":
            print("Weighted average (60% XGBoost, 40% ONNX)")
        elif strategy == "majority":
            print("Majority voting (binary decisions)")
        elif strategy == "unanimous":
            print("Unanimous voting (all models must agree)")
        
        # Extract features to show what's being predicted
        features = ensemble.extract_features(opportunity)
        print(f"   Features extracted: {features.shape}")
        print(f"   Sample features: profit=${features[0,0]:.2f}, "
              f"ratio={features[0,1]:.3f}, complexity={features[0,2]:.0f}\n")


def demo_data_collection():
    """Demo 4: Automated Retraining - Data Collection"""
    print_section("DEMO 4: Automated Retraining - Data Collection")
    
    collector = TrainingDataCollector()
    
    print("üìä Collecting training data from executions...\n")
    
    # Simulate collecting execution results
    for i in range(5):
        opportunity = {
            "route_id": f"route_{i}",
            "tokens": ["USDC", "USDT", "USDC"],
            "dexes": ["quickswap", "sushiswap"],
            "profit_usd": 10 + i * 2,
            "expected_output": 1000 + 10 + i * 2,
            "input_amount": 1000,
            "gas_estimate": 350000,
            "confidence_score": 0.85
        }
        
        # Simulate execution result
        prediction_score = 0.87
        actual_result = i % 4 != 0  # 75% success rate
        profit_usd = opportunity["profit_usd"] if actual_result else -2.0
        execution_time_ms = 2.5
        
        collector.add_execution_result(
            opportunity=opportunity,
            prediction_score=prediction_score,
            actual_result=actual_result,
            profit_usd=profit_usd,
            execution_time_ms=execution_time_ms
        )
        
        status = "‚úÖ Success" if actual_result else "‚ùå Failed"
        print(f"   Execution {i+1}: {status} | Profit: ${profit_usd:.2f}")
    
    print(f"\nüíæ Collected {len(collector.batch_data)} execution records")
    print(f"   Data saved to: {collector.current_batch_file}")


def demo_gpu_acceleration():
    """Demo 5: GPU Acceleration Support"""
    print_section("DEMO 5: GPU Acceleration Support")
    
    print("üöÄ Testing GPU acceleration...\n")
    
    # Test CPU
    print("1Ô∏è‚É£  CPU Mode:")
    ensemble_cpu = MLEnsemble(use_gpu=False)
    print(f"   Providers: {ensemble_cpu.providers}\n")
    
    # Test GPU (if available)
    print("2Ô∏è‚É£  GPU Mode (CUDA):")
    ensemble_gpu = MLEnsemble(use_gpu=True)
    print(f"   Providers: {ensemble_gpu.providers}")
    
    if 'CUDAExecutionProvider' in ensemble_gpu.providers:
        print("   ‚úÖ GPU acceleration is AVAILABLE")
    else:
        print("   ‚ö†Ô∏è  GPU not available (using CPU fallback)")
    
    print("\nüìù Notes:")
    print("   - GPU acceleration requires CUDA-enabled GPU")
    print("   - Install: pip install onnxruntime-gpu")
    print("   - Provides 10-100x speedup for inference")


async def demo_batch_prediction():
    """Demo 1: Batch Prediction (simulated without server)"""
    print_section("DEMO 1: Batch Prediction Endpoint")
    
    print("üì¶ Simulating batch prediction for multiple opportunities...\n")
    
    # Create multiple opportunities
    opportunities = []
    for i in range(10):
        opp = Opportunity(
            route_id=f"route_{i}",
            tokens=["USDC", "USDT", "USDC"],
            dexes=["quickswap", "sushiswap"],
            input_amount=1000.0 + i * 100,
            expected_output=1010.0 + i * 100,
            gas_estimate=350000,
            profit_usd=10.0 + i,
            confidence_score=0.80 + i * 0.01,
            timestamp=int(time.time()),
            chain=ChainType.POLYGON
        )
        opportunities.append(opp)
    
    # Simulate batch processing
    print(f"Processing {len(opportunities)} opportunities...")
    
    start_time = time.time()
    ensemble = MLEnsemble(use_gpu=False, voting_strategy="weighted")
    
    results = []
    for opp in opportunities:
        score = ensemble.predict(opp)
        should_execute = score > 0.8
        results.append((opp.route_id, score, should_execute))
    
    total_time = (time.time() - start_time) * 1000
    
    print(f"\n‚úÖ Batch prediction completed in {total_time:.2f}ms")
    print(f"   Average time per opportunity: {total_time/len(opportunities):.2f}ms\n")
    
    print("üìä Results:")
    executable = 0
    for route_id, score, should_exec in results[:5]:  # Show first 5
        status = "‚úÖ EXECUTE" if should_exec else "‚è≠Ô∏è  SKIP"
        print(f"   {route_id}: Score={score:.4f} | {status}")
        if should_exec:
            executable += 1
    
    print(f"\n   Total executable: {executable}/{len(opportunities)}")


def demo_websocket_info():
    """Demo 3: WebSocket Streaming (information only)"""
    print_section("DEMO 3: WebSocket Streaming for Real-Time Updates")
    
    print("üåê WebSocket Streaming Server\n")
    
    print("Features:")
    print("   ‚úÖ Real-time opportunity streaming")
    print("   ‚úÖ Live prediction results")
    print("   ‚úÖ Execution status updates")
    print("   ‚úÖ System metrics broadcasting")
    print("   ‚úÖ Multi-client support with heartbeat")
    
    print("\nUsage:")
    print("   1. Start server: python src/python/websocket_server.py")
    print("   2. Connect client: ws://localhost:8765")
    print("   3. Subscribe to channels via JSON messages")
    
    print("\nExample Messages:")
    print("   ‚Ä¢ Opportunity: {'type': 'opportunity', 'data': {...}}")
    print("   ‚Ä¢ Prediction: {'type': 'prediction', 'data': {...}}")
    print("   ‚Ä¢ Execution: {'type': 'execution', 'data': {...}}")
    print("   ‚Ä¢ Metrics: {'type': 'metrics', 'data': {...}}")
    
    print("\nCommands:")
    print("   ‚Ä¢ Subscribe: {'command': 'subscribe', 'channels': [...]}")
    print("   ‚Ä¢ Get stats: {'command': 'stats'}")
    print("   ‚Ä¢ Ping: {'command': 'ping'}")


async def main():
    """Run all demonstrations"""
    print("\n" + "=" * 70)
    print("  üöÄ APEX ML SYSTEM ENHANCEMENTS - DEMONSTRATION")
    print("=" * 70)
    print("\nThis demo showcases all 6 major enhancements:\n")
    print("1. ‚úÖ Batch prediction endpoint for multiple opportunities")
    print("2. ‚úÖ Model versioning and A/B testing")
    print("3. ‚úÖ WebSocket streaming for real-time updates")
    print("4. ‚úÖ Automated model retraining on new data")
    print("5. ‚úÖ GPU acceleration support")
    print("6. ‚úÖ Multi-model ensemble voting")
    
    input("\n‚è∏Ô∏è  Press ENTER to start demonstrations...")
    
    # Run demos
    demo_model_versioning()
    input("\n‚è∏Ô∏è  Press ENTER for next demo...")
    
    await demo_batch_prediction()
    input("\n‚è∏Ô∏è  Press ENTER for next demo...")
    
    demo_websocket_info()
    input("\n‚è∏Ô∏è  Press ENTER for next demo...")
    
    demo_data_collection()
    input("\n‚è∏Ô∏è  Press ENTER for next demo...")
    
    demo_gpu_acceleration()
    input("\n‚è∏Ô∏è  Press ENTER for next demo...")
    
    demo_ensemble_voting()
    
    # Summary
    print_section("SUMMARY")
    print("‚úÖ All 6 enhancements have been successfully demonstrated!\n")
    
    print("Next Steps:")
    print("1. Start ML API Server: python src/python/ml_api_server.py")
    print("2. Start WebSocket Server: python src/python/websocket_server.py")
    print("3. Train models and test retraining pipeline")
    print("4. Setup A/B tests for production models")
    print("5. Monitor performance and metrics")
    
    print("\nDocumentation:")
    print("‚Ä¢ API Endpoints: http://localhost:8000/docs (FastAPI auto-docs)")
    print("‚Ä¢ WebSocket: ws://localhost:8765")
    print("‚Ä¢ Model Manager: See model_manager.py")
    print("‚Ä¢ Retraining: See retraining_pipeline.py")


if __name__ == "__main__":
    asyncio.run(main())
